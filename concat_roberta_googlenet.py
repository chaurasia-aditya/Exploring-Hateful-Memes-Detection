# -*- coding: utf-8 -*-
"""concat-roberta-googlenet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FOCuPEdR7C14pF_2efhMvPw9NyIZu3N1
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

! pip install transformers
! pip install datasets
! pip install --upgrade tqdm
! pip install pytorch-lightning

!pip install torcheval

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2

# torch
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
from torch.utils.data import Dataset, DataLoader
from torcheval.metrics.functional import binary_auroc

# data
# from HMDataset import HMDataset, HMDataset_H5

# model
from transformers import RobertaModel, RobertaTokenizerFast
# from ClassificationHead import BaseLineHead

# general
import os
from PIL import Image
import requests
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm import tqdm
import cv2

# gpu check
print(torch.__version__)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device=='cuda')

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
path = '/content/drive/MyDrive/Assignment_2/'
# %cd /content/drive/MyDrive/Assignment_2/
!unzip hateful_memes

path = '/content/drive/MyDrive/Assignment_2/hateful_memes/'

import pandas as pd
val_seen = pd.read_json(path+'dev_seen.jsonl',lines=True)
val_unseen= pd.read_json(path+'dev_unseen.jsonl',lines=True)
test_seen=pd.read_json(path+'test_seen.jsonl',lines=True)
test_unseen=pd.read_json(path+'test_unseen.jsonl',lines=True)
df_train =pd.read_json(path+'train.jsonl',lines=True)

df_train.label.value_counts()

val_seen.label.value_counts()

class HatefulMemesDataset(Dataset):
    def __init__(self, jsonl_file, root_dir, transform=None):
        self.annotations = pd.read_json(jsonl_file, lines=True)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        id = self.annotations.loc[idx, 'id']
        img_path = os.path.join(self.root_dir, self.annotations.loc[idx, 'img'])
        label = self.annotations.loc[idx, 'label']
        text = self.annotations.loc[idx, 'text']

        try:
            # Load image
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Apply transformations
            if self.transform:
                image = self.transform(image)

            sample = {"id": id, "image": image, "label": label, "text": text}

            return sample

        except Exception as e:
            print(f"Error loading image at index {idx}: {e}")
            return None

hm_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
])

train_jsonl = os.path.join(path, "train.jsonl")
val_seen_jsonl = os.path.join(path, "dev_seen.jsonl")
val_unseen_jsonl = os.path.join(path, "dev_unseen.jsonl")
test_seen_jsonl = os.path.join(path, "test_seen.jsonl")
test_unseen_jsonl = os.path.join(path, "test_unseen.jsonl")

# Create datasets
train_dataset = HatefulMemesDataset(jsonl_file=train_jsonl, root_dir=path, transform=hm_transform)
val_seen_dataset = HatefulMemesDataset(jsonl_file=val_seen_jsonl, root_dir=path, transform=hm_transform)
val_unseen_dataset = HatefulMemesDataset(jsonl_file=val_unseen_jsonl, root_dir=path, transform=hm_transform)
test_seen_dataset = HatefulMemesDataset(jsonl_file=test_seen_jsonl, root_dir=path, transform=hm_transform)
test_unseen_dataset = HatefulMemesDataset(jsonl_file=test_unseen_jsonl, root_dir=path, transform=hm_transform)

# Hyperparameters
batch_size = 64

train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_seen_dataloader = DataLoader(val_seen_dataset, batch_size=batch_size, shuffle=False)
val_unseen_dataloader = DataLoader(val_unseen_dataset, batch_size=batch_size, shuffle=False)
test_seen_dataloader = DataLoader(test_seen_dataset, batch_size=batch_size, shuffle=False)
test_unseen_dataloader = DataLoader(test_unseen_dataset, batch_size=batch_size, shuffle=False)

from torch.utils.data import ConcatDataset

# Combine datasets
val_dataset = ConcatDataset([val_seen_dataset, val_unseen_dataset])
# Combine data loaders
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# Combine datasets
test_dataset = ConcatDataset([test_seen_dataset, test_unseen_dataset])
# Combine data loaders
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

"""GoogleNet"""

# Load pre-trained GoogLeNet model
googlenet = models.googlenet(pretrained=True).to(device)

# Remove the classifier (top) layer
modules = list(googlenet.children())[:-1]
googlenet_fe = nn.Sequential(*modules)

# Freeze the parameters of the feature extraction layers
for p in googlenet_fe.parameters():
    p.requires_grad = False

"""# ROBERTA"""

tokenizer = RobertaTokenizerFast.from_pretrained("roberta-base")
roberta_model = RobertaModel.from_pretrained("roberta-base")

roberta_model.to(device)

for param in roberta_model.parameters():
    param.requires_grad = False

class BaseLineHead(nn.Module):
    def __init__(self):
        super().__init__()

        self.linear_stack = nn.Sequential(
            nn.BatchNorm1d(1792), # test add batchnorm, b/c image and text encoding have diff ranges
            nn.Linear(1792, 1024),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(1024, 2),
        )

    def forward(self, x):
        logits = self.linear_stack(x)
        return logits

head = BaseLineHead()
head.to(device)

def get_metrics_and_losses(losses, predictions, labels):
  average_loss = losses.mean().item()
  accuracy = (predictions == labels).sum().item() / labels.numel()

  # print(predictions)
  # print(labels)
  auroc = binary_auroc(predictions, labels)

  return average_loss, accuracy, auroc

"""# Test on 1 Batch"""

sample_test = next(iter(test_seen_dataloader))

text = sample_test['text']
image = sample_test['image'].to(device)
labels = sample_test['label'].to(device).to(torch.int64)

id = sample_test["id"]

print(image.shape)

print(id[0])
print(text[0])
print(labels[0])
plt.imshow(image[0].cpu().detach().numpy().transpose(1, 2, 0))

sample_valid = next(iter(val_seen_dataloader))

text = sample_valid['text']
image = sample_valid['image'].to(device)
labels = sample_valid['label'].to(device).to(torch.int64)

id = sample_valid["id"]

print(image.shape)

print(id[0])
print(text[0])
print(labels[0])
plt.imshow(image[0].cpu().detach().numpy().transpose(1, 2, 0))
print(image[0].dtype)

image = image.float()
image_features = googlenet_fe(image).squeeze()

print(image_features.shape)
print(image_features)

print(torch.max(image_features))
print(torch.min(image_features))

sample_batch = next(iter(train_dataloader))

# get inputs
text = sample_batch['text']
image = sample_batch['image'].to(device)
labels = sample_batch['label'].to(device).to(torch.int64)

print(image.shape)

print(text[0])
print(labels[0])

# plt.imshow(image[0].to(torch.int64).cpu().detach().numpy().transpose(1, 2, 0))
plt.imshow(image[0].cpu().detach().numpy().transpose(1, 2, 0))
print(image[0].dtype)

image = image.float()
image_features = googlenet_fe(image).squeeze()

print(image_features.shape)
print(image_features)

print(torch.max(image_features))
print(torch.min(image_features))

# Get Text Features

tokenized_input = tokenizer(text, padding=True, return_tensors="pt").to(device)
text_features = roberta_model(**tokenized_input)

print(text_features["pooler_output"].shape)
print(text_features["pooler_output"])

print(torch.max(text_features["pooler_output"]))
print(torch.min(text_features["pooler_output"]))

# concatenate both features

concat_features = torch.cat((image_features, text_features["pooler_output"]), dim=1)

print(concat_features.shape)
print(concat_features)

print(torch.min(concat_features))
print(torch.max(concat_features))

batchnorm = nn.BatchNorm1d(1792).to(device)

normalized_features = batchnorm(concat_features)

print(normalized_features.shape)
print(normalized_features)

print(torch.min(normalized_features))
print(torch.max(normalized_features))

softmax = nn.Softmax(dim=-1)

scores = head(concat_features)

pred = scores.argmax(dim=-1)

print(scores)
print(pred)
print(labels)

"""# Train Model"""

head = BaseLineHead()
head.to(device)

lr = 1e-4
epochs = 10
weight_decay = 1e-3

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(head.parameters(), lr=lr, weight_decay=weight_decay)

loss = criterion(scores, labels)
print(loss)

loss, acc, auroc = get_metrics_and_losses(loss, pred, labels)

print(loss)
print(acc)
print(auroc)

"""# Training Loop"""

model_path ='/content/drive/MyDrive/Assignment_2/hateful_memes/'

!mkdir -p models

# train model head
max_validation_auroc = 0

for e in range(epochs):

  # training
  train_losses = torch.zeros(len(train_dataloader)).to(device)
  train_predictions = torch.Tensor().to(device)
  train_labels = torch.Tensor().to(device)

  googlenet_fe.train()
  roberta_model.train()
  head.train()

  for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc="Epoch " + str(e+1) + " Training"):

    # get inputs
    text = data['text']
    image = data['image'].to(device).float()
    labels = data['label'].to(device).to(torch.int64)

    # zero the parameter gradients
    optimizer.zero_grad()


    # GoogleNet Image Features
    image_features = googlenet_fe(image).squeeze()

    # BERT Text Features
    tokenized_input = tokenizer(text, padding=True, return_tensors="pt").to(device)
    text_features = roberta_model(**tokenized_input)

    # print("after-BERT")

    # Concatenate Features
    concat_features = torch.cat((image_features, text_features["pooler_output"]), dim=1)

    # print("pre-head")

    # classification head
    scores = torch.squeeze(head(concat_features))
    predictions = scores.argmax(dim=-1)

    # print("after-head")
    # print("pre-backprop")

    # backprop
    loss = criterion(scores, labels)
    loss.backward()
    optimizer.step()

    # print("after-backprop")

    # track values for metric logging
    train_losses[i] = loss
    train_predictions = torch.cat((train_predictions, predictions))
    train_labels = torch.cat((train_labels, labels))

    train_average_loss, train_accuracy, train_auroc = get_metrics_and_losses(train_losses, train_predictions, train_labels)

  # validation
  validate_losses = torch.zeros(len(val_dataloader)).to(device)
  validate_predictions = torch.Tensor().to(device)
  validate_labels = torch.Tensor().to(device)

  googlenet_fe.eval()
  roberta_model.eval()
  head.eval()

  with torch.no_grad():
    for i, data in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc="Epoch " + str(e+1) + " Validation"):

      # get inputs
      # get inputs
      text = data['text']
      image = data['image'].to(device).float()
      labels = data['label'].to(device).to(torch.int64)

      # GoogleNet Image Features
      image_features = googlenet_fe(image).squeeze()

      # BERT Text Features
      tokenized_input = tokenizer(text, padding=True, return_tensors="pt").to(device)
      text_features = roberta_model(**tokenized_input)

      # Concatenate Features
      concat_features = torch.cat((image_features, text_features["pooler_output"]), dim=1)

      # classification head
      scores = torch.squeeze(head(concat_features))
      predictions = scores.argmax(dim=-1)

      # loss
      loss = criterion(scores, labels)

      # track values for metric logging
      validate_losses[i] = loss
      validate_predictions = torch.cat((validate_predictions, predictions), dim=0)
      validate_labels = torch.cat((validate_labels, labels), dim=0)

  validate_average_loss, validate_accuracy, validate_auroc = get_metrics_and_losses(validate_losses, validate_predictions, validate_labels)

  # save model
  if validate_auroc > max_validation_auroc:
    max_validation_auroc = validate_auroc
    torch.save(head, model_path +"/concat_roberta_" + str(e+1) + ".pt")
    print("New model saved at epoch " + str(e+1))

  print(train_predictions[:64])
  print(train_labels[:64])
  print(validate_predictions[:64])
  print(validate_labels[:64])

  print("Epoch %d" % (e+1))
  print("Training Loss: %.4f. Validation Loss: %.4f. " % (train_average_loss, validate_average_loss))
  print("Training Accuracy: %.4f. Validation Accuracy: %.4f. " % (train_accuracy, validate_accuracy))
  print("Training AUROC: %.4f. Validation AUROC: %.4f. " % (train_auroc, validate_auroc))
  print("-----------------------------------")


  # looks promising on training - failing to generalize = overfitting
  # add batchnorm (done)
  # inc dropout (done)
  # remove middle layer (not much effect - try reducing hidden size)
  # add weight decay - essentialy explicit L2 regularization -> **best results so far**
  # implement early stopping
  # incr to 20 epochs? -> 40 mins to train...

  # try without sigmoid - maybe better

