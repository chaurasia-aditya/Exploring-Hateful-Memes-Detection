{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8103859,"sourceType":"datasetVersion","datasetId":4786064}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers\n! pip install datasets \n! pip install --upgrade tqdm\n! pip install torcheval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-01T04:40:54.377860Z","iopub.execute_input":"2024-05-01T04:40:54.378149Z","iopub.status.idle":"2024-05-01T04:41:42.892960Z","shell.execute_reply.started":"2024-05-01T04:40:54.378122Z","shell.execute_reply":"2024-05-01T04:41:42.891944Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.2)\nRequirement already satisfied: torcheval in /opt/conda/lib/python3.10/site-packages (0.0.7)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path =\"/kaggle/working/models/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:41:42.894239Z","iopub.execute_input":"2024-05-01T04:41:42.894557Z","iopub.status.idle":"2024-05-01T04:41:42.899133Z","shell.execute_reply.started":"2024-05-01T04:41:42.894530Z","shell.execute_reply":"2024-05-01T04:41:42.898190Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!mkdir -p models","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:41:42.900241Z","iopub.execute_input":"2024-05-01T04:41:42.900519Z","iopub.status.idle":"2024-05-01T04:41:43.842155Z","shell.execute_reply.started":"2024-05-01T04:41:42.900497Z","shell.execute_reply":"2024-05-01T04:41:43.840941Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torcheval.metrics.functional import binary_auroc\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom transformers import RobertaModel, RobertaTokenizerFast\n\nimport os\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:07.622671Z","iopub.execute_input":"2024-05-01T04:42:07.623364Z","iopub.status.idle":"2024-05-01T04:42:15.753029Z","shell.execute_reply.started":"2024-05-01T04:42:07.623322Z","shell.execute_reply":"2024-05-01T04:42:15.752225Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device=='cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:15.754670Z","iopub.execute_input":"2024-05-01T04:42:15.755095Z","iopub.status.idle":"2024-05-01T04:42:15.827618Z","shell.execute_reply.started":"2024-05-01T04:42:15.755069Z","shell.execute_reply":"2024-05-01T04:42:15.826619Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2.1.2\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/facebook-hateful-memes/hateful_memes/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:15.828927Z","iopub.execute_input":"2024-05-01T04:42:15.829238Z","iopub.status.idle":"2024-05-01T04:42:15.880651Z","shell.execute_reply.started":"2024-05-01T04:42:15.829213Z","shell.execute_reply":"2024-05-01T04:42:15.879777Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nval_seen = pd.read_json(path+'dev_seen.jsonl',lines=True)\nval_unseen= pd.read_json(path+'dev_unseen.jsonl',lines=True)\ntest_seen=pd.read_json(path+'test_seen.jsonl',lines=True)\ntest_unseen=pd.read_json(path+'test_unseen.jsonl',lines=True)\ndf_train =pd.read_json(path+'train.jsonl',lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:15.883732Z","iopub.execute_input":"2024-05-01T04:42:15.884009Z","iopub.status.idle":"2024-05-01T04:42:16.053287Z","shell.execute_reply.started":"2024-05-01T04:42:15.883986Z","shell.execute_reply":"2024-05-01T04:42:16.052382Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class HatefulMemesDataset(Dataset):\n    def __init__(self, jsonl_file, root_dir, transform=None):\n        self.annotations = pd.read_json(jsonl_file, lines=True)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        id = self.annotations.loc[idx, 'id']\n        img_path = os.path.join(self.root_dir, self.annotations.loc[idx, 'img'])\n        label = self.annotations.loc[idx, 'label']\n        text = self.annotations.loc[idx, 'text']\n\n        try:\n            # Load image\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # Apply transformations\n            if self.transform:\n                image = self.transform(image)\n\n            sample = {\"id\": id, \"image\": image, \"label\": label, \"text\": text}\n\n            return sample\n\n        except Exception as e:\n            print(f\"Error loading image at index {idx}: {e}\")\n            return None","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.054563Z","iopub.execute_input":"2024-05-01T04:42:16.054860Z","iopub.status.idle":"2024-05-01T04:42:16.110958Z","shell.execute_reply.started":"2024-05-01T04:42:16.054835Z","shell.execute_reply":"2024-05-01T04:42:16.110007Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"hm_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.111963Z","iopub.execute_input":"2024-05-01T04:42:16.112225Z","iopub.status.idle":"2024-05-01T04:42:16.163141Z","shell.execute_reply.started":"2024-05-01T04:42:16.112202Z","shell.execute_reply":"2024-05-01T04:42:16.162310Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_jsonl = os.path.join(path, \"train.jsonl\")\nval_seen_jsonl = os.path.join(path, \"dev_seen.jsonl\")\nval_unseen_jsonl = os.path.join(path, \"dev_unseen.jsonl\")\ntest_seen_jsonl = os.path.join(path, \"test_seen.jsonl\")\ntest_unseen_jsonl = os.path.join(path, \"test_unseen.jsonl\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.164271Z","iopub.execute_input":"2024-05-01T04:42:16.164777Z","iopub.status.idle":"2024-05-01T04:42:16.218394Z","shell.execute_reply.started":"2024-05-01T04:42:16.164752Z","shell.execute_reply":"2024-05-01T04:42:16.217457Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = HatefulMemesDataset(jsonl_file=train_jsonl, root_dir=path, transform=hm_transform)\nval_seen_dataset = HatefulMemesDataset(jsonl_file=val_seen_jsonl, root_dir=path, transform=hm_transform)\nval_unseen_dataset = HatefulMemesDataset(jsonl_file=val_unseen_jsonl, root_dir=path, transform=hm_transform)\ntest_seen_dataset = HatefulMemesDataset(jsonl_file=test_seen_jsonl, root_dir=path, transform=hm_transform)\ntest_unseen_dataset = HatefulMemesDataset(jsonl_file=test_unseen_jsonl, root_dir=path, transform=hm_transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.219520Z","iopub.execute_input":"2024-05-01T04:42:16.220289Z","iopub.status.idle":"2024-05-01T04:42:16.337794Z","shell.execute_reply.started":"2024-05-01T04:42:16.220264Z","shell.execute_reply":"2024-05-01T04:42:16.337063Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.338850Z","iopub.execute_input":"2024-05-01T04:42:16.339141Z","iopub.status.idle":"2024-05-01T04:42:16.390447Z","shell.execute_reply.started":"2024-05-01T04:42:16.339118Z","shell.execute_reply":"2024-05-01T04:42:16.389587Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# val_seen_dataloader = DataLoader(val_seen_dataset, batch_size=batch_size, shuffle=False)\n# val_unseen_dataloader = DataLoader(val_unseen_dataset, batch_size=batch_size, shuffle=False)\n# test_seen_dataloader = DataLoader(test_seen_dataset, batch_size=batch_size, shuffle=False)\n# test_unseen_dataloader = DataLoader(test_unseen_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.393236Z","iopub.execute_input":"2024-05-01T04:42:16.393610Z","iopub.status.idle":"2024-05-01T04:42:16.446608Z","shell.execute_reply.started":"2024-05-01T04:42:16.393585Z","shell.execute_reply":"2024-05-01T04:42:16.445643Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"val_dataset = ConcatDataset([val_seen_dataset, val_unseen_dataset])\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.447834Z","iopub.execute_input":"2024-05-01T04:42:16.448469Z","iopub.status.idle":"2024-05-01T04:42:16.500554Z","shell.execute_reply.started":"2024-05-01T04:42:16.448436Z","shell.execute_reply":"2024-05-01T04:42:16.499707Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_dataset = ConcatDataset([test_seen_dataset, test_unseen_dataset])\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.501637Z","iopub.execute_input":"2024-05-01T04:42:16.501903Z","iopub.status.idle":"2024-05-01T04:42:16.550854Z","shell.execute_reply.started":"2024-05-01T04:42:16.501881Z","shell.execute_reply":"2024-05-01T04:42:16.549949Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"def get_metrics_and_losses(losses, predictions, labels):\n  average_loss = losses.mean().item()\n  accuracy = (predictions == labels).sum().item() / labels.numel()\n  auroc = binary_auroc(predictions, labels)\n\n  return average_loss, accuracy, auroc","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.552095Z","iopub.execute_input":"2024-05-01T04:42:16.552456Z","iopub.status.idle":"2024-05-01T04:42:16.602941Z","shell.execute_reply.started":"2024-05-01T04:42:16.552425Z","shell.execute_reply":"2024-05-01T04:42:16.602182Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Resnet152","metadata":{}},{"cell_type":"code","source":"resnet152 = models.resnet152(pretrained=True)\nresnet152_fe = nn.Sequential(*list(resnet152.children())[:-1])\nfor p in resnet152_fe.parameters():\n    p.requires_grad = False\nresnet152_fe.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:16.604044Z","iopub.execute_input":"2024-05-01T04:42:16.604322Z","iopub.status.idle":"2024-05-01T04:42:33.016718Z","shell.execute_reply.started":"2024-05-01T04:42:16.604300Z","shell.execute_reply":"2024-05-01T04:42:33.015791Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n100%|██████████| 230M/230M [00:13<00:00, 17.6MB/s] \n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (23): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (24): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (25): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (26): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (27): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (28): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (29): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (30): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (31): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (32): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (33): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (34): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (35): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# RoBERTa","metadata":{}},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\nroberta_model = RobertaModel.from_pretrained(\"roberta-base\")\nfor param in roberta_model.parameters():\n    param.requires_grad = False\nroberta_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:33.017950Z","iopub.execute_input":"2024-05-01T04:42:33.018234Z","iopub.status.idle":"2024-05-01T04:42:52.154229Z","shell.execute_reply.started":"2024-05-01T04:42:33.018210Z","shell.execute_reply":"2024-05-01T04:42:52.153272Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d33432c461841ef82d393a267f34296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca015d2f76ab44c1861f71638839ef4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfec6c6ea33465da534f3c551ba1f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e4a705c6ebf4d838c5e37627017b9d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8611a38fac42de8a9eee12288a9498"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91258a6ac7b49efba89df976ec2c5d8"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Head","metadata":{}},{"cell_type":"code","source":"class SimpleHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.linear_stack = nn.Sequential(\n            nn.BatchNorm1d(2816),\n            nn.Linear(2816, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 2),\n        )\n    \n    def forward(self, x):\n        logits = self.linear_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:52.157479Z","iopub.execute_input":"2024-05-01T04:42:52.157942Z","iopub.status.idle":"2024-05-01T04:42:52.211647Z","shell.execute_reply.started":"2024-05-01T04:42:52.157907Z","shell.execute_reply":"2024-05-01T04:42:52.210689Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"head = SimpleHead()\nhead.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:42:52.212794Z","iopub.execute_input":"2024-05-01T04:42:52.213137Z","iopub.status.idle":"2024-05-01T04:42:52.291666Z","shell.execute_reply.started":"2024-05-01T04:42:52.213105Z","shell.execute_reply":"2024-05-01T04:42:52.290854Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"SimpleHead(\n  (linear_stack): Sequential(\n    (0): BatchNorm1d(2816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Linear(in_features=2816, out_features=1024, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=1024, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"lr = 1e-5\nepochs = 40\nweight_decay = 1e-3\naccumulate_steps = 4\n\n# Define criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Define optimizer\noptimizer = optim.Adam(head.parameters(), lr=lr, weight_decay=weight_decay)\n\n# Initialize learning rate scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n\n# Initialize early stopping parameters\nearly_stopping_counter = 0\nearly_stopping_patience = 5\nbest_validation_auroc = float('-inf')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:46:46.579005Z","iopub.execute_input":"2024-05-01T04:46:46.579835Z","iopub.status.idle":"2024-05-01T04:46:46.636474Z","shell.execute_reply.started":"2024-05-01T04:46:46.579802Z","shell.execute_reply":"2024-05-01T04:46:46.635379Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Train model head\nfor e in range(epochs):\n    # Training\n    train_losses = []\n    train_predictions = []\n    train_labels = []\n\n    roberta_model.train()\n    optimizer.zero_grad()\n\n    for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Epoch \" + str(e+1) + \" Training\"):\n        text = data['text']\n        image = data['image'].to(device).float()\n        labels = data['label'].to(device).to(torch.int64)\n\n        image_features = resnet152_fe(image).squeeze()\n\n        tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n        text_features = roberta_model(**tokenized_input)\n\n        concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n        scores = torch.squeeze(head(concat_features))\n        predictions = scores.argmax(dim=-1)\n\n        loss = criterion(scores, labels)\n        loss.backward()\n\n        if (i + 1) % accumulate_steps == 0 or i == len(train_dataloader) - 1:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        train_losses.append(loss.item())\n        train_predictions.extend(predictions.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n    train_average_loss, train_accuracy, train_auroc = get_metrics_and_losses(torch.tensor(train_losses), torch.tensor(train_predictions), torch.tensor(train_labels))\n\n    # Validation\n    validate_losses = torch.zeros(len(val_dataloader)).to(device)\n    validate_predictions = torch.Tensor().to(device)\n    validate_labels = torch.Tensor().to(device)\n\n    resnet152_fe.eval()\n    roberta_model.eval()\n    head.eval()\n\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=\"Epoch \" + str(e+1) + \" Validation\"):\n            text = data['text']\n            image = data['image'].to(device).float()\n            labels = data['label'].to(device).to(torch.int64)\n\n            image_features = resnet152_fe(image).squeeze()\n\n            tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n            text_features = roberta_model(**tokenized_input)\n\n            concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n            scores = torch.squeeze(head(concat_features))\n            predictions = scores.argmax(dim=-1)\n\n            loss = criterion(scores, labels)\n\n            validate_losses[i] = loss\n            validate_predictions = torch.cat((validate_predictions, predictions), dim=0)\n            validate_labels = torch.cat((validate_labels, labels), dim=0)\n\n    validate_average_loss, validate_accuracy, validate_auroc = get_metrics_and_losses(validate_losses, validate_predictions, validate_labels)\n\n    # Update learning rate scheduler\n    scheduler.step(validate_auroc)\n\n    # Early stopping\n    if validate_auroc > best_validation_auroc:\n        best_validation_auroc = validate_auroc\n        early_stopping_counter = 0\n        # Save the best model\n        torch.save(head, model_path + \"/concat_roberta_best.pt\")\n        print(\"New best model saved at epoch\", e+1)\n    else:\n        early_stopping_counter += 1\n        if early_stopping_counter >= early_stopping_patience:\n            print(\"Early stopping triggered at epoch\", e+1)\n            break\n\n    # Additional logging or tasks can be performed here\n    print(\"Epoch %d\" % (e+1))\n    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (train_average_loss, validate_average_loss))\n    print(\"Training Accuracy: %.4f. Validation Accuracy: %.4f. \" % (train_accuracy, validate_accuracy))\n    print(\"Training AUROC: %.4f. Validation AUROC: %.4f. \" % (train_auroc, validate_auroc))\n    print(\"-----------------------------------\")\n\nprint(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T04:46:48.079406Z","iopub.execute_input":"2024-05-01T04:46:48.079786Z","iopub.status.idle":"2024-05-01T05:29:32.281994Z","shell.execute_reply.started":"2024-05-01T04:46:48.079755Z","shell.execute_reply":"2024-05-01T05:29:32.281086Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Epoch 1 Training: 100%|██████████| 532/532 [03:48<00:00,  2.33it/s]\nEpoch 1 Validation: 100%|██████████| 65/65 [00:25<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 1\nEpoch 1\nTraining Loss: 0.6568. Validation Loss: 0.6987. \nTraining Accuracy: 0.6129. Validation Accuracy: 0.5625. \nTraining AUROC: 0.5317. Validation AUROC: 0.5023. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 Training: 100%|██████████| 532/532 [03:06<00:00,  2.86it/s]\nEpoch 2 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 2\nEpoch 2\nTraining Loss: 0.6239. Validation Loss: 0.7026. \nTraining Accuracy: 0.6562. Validation Accuracy: 0.5625. \nTraining AUROC: 0.5374. Validation AUROC: 0.5065. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Training: 100%|██████████| 532/532 [03:08<00:00,  2.83it/s]\nEpoch 3 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\nTraining Loss: 0.6059. Validation Loss: 0.7062. \nTraining Accuracy: 0.6711. Validation Accuracy: 0.5615. \nTraining AUROC: 0.5630. Validation AUROC: 0.5040. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Training: 100%|██████████| 532/532 [03:07<00:00,  2.83it/s]\nEpoch 4 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 4\nEpoch 4\nTraining Loss: 0.5948. Validation Loss: 0.7080. \nTraining Accuracy: 0.6832. Validation Accuracy: 0.5654. \nTraining AUROC: 0.5792. Validation AUROC: 0.5115. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 Training: 100%|██████████| 532/532 [03:08<00:00,  2.83it/s]\nEpoch 5 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 5\nEpoch 5\nTraining Loss: 0.5826. Validation Loss: 0.7127. \nTraining Accuracy: 0.6956. Validation Accuracy: 0.5712. \nTraining AUROC: 0.6003. Validation AUROC: 0.5146. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 Training: 100%|██████████| 532/532 [03:07<00:00,  2.84it/s]\nEpoch 6 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 6\nEpoch 6\nTraining Loss: 0.5733. Validation Loss: 0.7156. \nTraining Accuracy: 0.7072. Validation Accuracy: 0.5740. \nTraining AUROC: 0.6124. Validation AUROC: 0.5163. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 Training: 100%|██████████| 532/532 [03:08<00:00,  2.82it/s]\nEpoch 7 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 7\nEpoch 7\nTraining Loss: 0.5634. Validation Loss: 0.7172. \nTraining Accuracy: 0.7144. Validation Accuracy: 0.5798. \nTraining AUROC: 0.6244. Validation AUROC: 0.5261. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 Training: 100%|██████████| 532/532 [03:06<00:00,  2.85it/s]\nEpoch 8 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8\nTraining Loss: 0.5551. Validation Loss: 0.7240. \nTraining Accuracy: 0.7207. Validation Accuracy: 0.5712. \nTraining AUROC: 0.6335. Validation AUROC: 0.5143. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 Training: 100%|██████████| 532/532 [03:06<00:00,  2.85it/s]\nEpoch 9 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9\nTraining Loss: 0.5441. Validation Loss: 0.7255. \nTraining Accuracy: 0.7352. Validation Accuracy: 0.5721. \nTraining AUROC: 0.6509. Validation AUROC: 0.5152. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 Training: 100%|██████████| 532/532 [03:07<00:00,  2.83it/s]\nEpoch 10 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10\nTraining Loss: 0.5375. Validation Loss: 0.7218. \nTraining Accuracy: 0.7346. Validation Accuracy: 0.5673. \nTraining AUROC: 0.6523. Validation AUROC: 0.5134. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 Training: 100%|██████████| 532/532 [03:06<00:00,  2.85it/s]\nEpoch 11 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11\nTraining Loss: 0.5293. Validation Loss: 0.7328. \nTraining Accuracy: 0.7482. Validation Accuracy: 0.5779. \nTraining AUROC: 0.6714. Validation AUROC: 0.5208. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 Training: 100%|██████████| 532/532 [03:06<00:00,  2.85it/s]\nEpoch 12 Validation: 100%|██████████| 65/65 [00:22<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"Early stopping triggered at epoch 12\nTraining complete.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Rebuild the model architecture\nbest_head = torch.load(model_path + \"/concat_roberta_best.pt\")\nbest_head.to(device)\n\n# Load the saved head weights\n# best_head.load_state_dict(torch.load(model_path + \"/concat_roberta_best.pt\"))\n\n# Evaluate on test set\ntest_losses = torch.zeros(len(test_dataloader)).to(device)\ntest_predictions = torch.Tensor().to(device)\ntest_labels = torch.Tensor().to(device)\n\nbest_head.eval()  # Set the head to evaluation mode\n\nwith torch.no_grad():\n    for i, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing\"):\n        text = data['text']\n        image = data['image'].to(device).float()\n        labels = data['label'].to(device).to(torch.int64)\n\n        image_features = resnet152_fe(image).squeeze()\n\n        tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n        text_features = roberta_model(**tokenized_input)\n\n        concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n        scores = torch.squeeze(best_head(concat_features))\n        predictions = scores.argmax(dim=-1)\n\n        loss = criterion(scores, labels)\n\n        test_losses[i] = loss\n        test_predictions = torch.cat((test_predictions, predictions), dim=0)\n        test_labels = torch.cat((test_labels, labels), dim=0)\n\ntest_average_loss, test_accuracy, test_auroc = get_metrics_and_losses(test_losses, test_predictions, test_labels)\n\nprint(\"Test Loss: %.4f\" % test_average_loss)\nprint(\"Test Accuracy: %.4f\" % test_accuracy)\nprint(\"Test AUROC: %.4f\" % test_auroc)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:29:46.078881Z","iopub.execute_input":"2024-05-01T05:29:46.079266Z","iopub.status.idle":"2024-05-01T05:31:03.956108Z","shell.execute_reply.started":"2024-05-01T05:29:46.079229Z","shell.execute_reply":"2024-05-01T05:31:03.955191Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 188/188 [01:17<00:00,  2.42it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.6885\nTest Accuracy: 0.5883\nTest AUROC: 0.5199\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}