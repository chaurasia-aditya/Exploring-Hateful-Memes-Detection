{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8103859,"sourceType":"datasetVersion","datasetId":4786064}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers\n! pip install datasets \n! pip install --upgrade tqdm\n! pip install torcheval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-01T05:43:39.655006Z","iopub.execute_input":"2024-05-01T05:43:39.655385Z","iopub.status.idle":"2024-05-01T05:44:29.778159Z","shell.execute_reply.started":"2024-05-01T05:43:39.655358Z","shell.execute_reply":"2024-05-01T05:44:29.777242Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nCollecting tqdm\n  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tqdm\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.66.1\n    Uninstalling tqdm-4.66.1:\n      Successfully uninstalled tqdm-4.66.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.6 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tqdm-4.66.2\nCollecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path =\"/kaggle/working/models/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:29.780132Z","iopub.execute_input":"2024-05-01T05:44:29.780422Z","iopub.status.idle":"2024-05-01T05:44:29.784770Z","shell.execute_reply.started":"2024-05-01T05:44:29.780393Z","shell.execute_reply":"2024-05-01T05:44:29.783795Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!mkdir -p models","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:29.785914Z","iopub.execute_input":"2024-05-01T05:44:29.786169Z","iopub.status.idle":"2024-05-01T05:44:30.736094Z","shell.execute_reply.started":"2024-05-01T05:44:29.786147Z","shell.execute_reply":"2024-05-01T05:44:30.734860Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torcheval.metrics.functional import binary_auroc\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom transformers import BertModel, BertTokenizerFast\n\nimport os\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:30.739282Z","iopub.execute_input":"2024-05-01T05:44:30.740102Z","iopub.status.idle":"2024-05-01T05:44:38.493790Z","shell.execute_reply.started":"2024-05-01T05:44:30.740062Z","shell.execute_reply":"2024-05-01T05:44:38.492703Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device=='cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.495090Z","iopub.execute_input":"2024-05-01T05:44:38.495651Z","iopub.status.idle":"2024-05-01T05:44:38.569558Z","shell.execute_reply.started":"2024-05-01T05:44:38.495616Z","shell.execute_reply":"2024-05-01T05:44:38.568527Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2.1.2\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/facebook-hateful-memes/hateful_memes/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.571051Z","iopub.execute_input":"2024-05-01T05:44:38.571876Z","iopub.status.idle":"2024-05-01T05:44:38.624688Z","shell.execute_reply.started":"2024-05-01T05:44:38.571842Z","shell.execute_reply":"2024-05-01T05:44:38.623799Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nval_seen = pd.read_json(path+'dev_seen.jsonl',lines=True)\nval_unseen= pd.read_json(path+'dev_unseen.jsonl',lines=True)\ntest_seen=pd.read_json(path+'test_seen.jsonl',lines=True)\ntest_unseen=pd.read_json(path+'test_unseen.jsonl',lines=True)\ndf_train =pd.read_json(path+'train.jsonl',lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.625927Z","iopub.execute_input":"2024-05-01T05:44:38.626239Z","iopub.status.idle":"2024-05-01T05:44:38.794541Z","shell.execute_reply.started":"2024-05-01T05:44:38.626215Z","shell.execute_reply":"2024-05-01T05:44:38.793591Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class HatefulMemesDataset(Dataset):\n    def __init__(self, jsonl_file, root_dir, transform=None):\n        self.annotations = pd.read_json(jsonl_file, lines=True)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        id = self.annotations.loc[idx, 'id']\n        img_path = os.path.join(self.root_dir, self.annotations.loc[idx, 'img'])\n        label = self.annotations.loc[idx, 'label']\n        text = self.annotations.loc[idx, 'text']\n\n        try:\n            # Load image\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # Apply transformations\n            if self.transform:\n                image = self.transform(image)\n\n            sample = {\"id\": id, \"image\": image, \"label\": label, \"text\": text}\n\n            return sample\n\n        except Exception as e:\n            print(f\"Error loading image at index {idx}: {e}\")\n            return None","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.795824Z","iopub.execute_input":"2024-05-01T05:44:38.796177Z","iopub.status.idle":"2024-05-01T05:44:38.854706Z","shell.execute_reply.started":"2024-05-01T05:44:38.796137Z","shell.execute_reply":"2024-05-01T05:44:38.853834Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"hm_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.856031Z","iopub.execute_input":"2024-05-01T05:44:38.856832Z","iopub.status.idle":"2024-05-01T05:44:38.909239Z","shell.execute_reply.started":"2024-05-01T05:44:38.856785Z","shell.execute_reply":"2024-05-01T05:44:38.908352Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_jsonl = os.path.join(path, \"train.jsonl\")\nval_seen_jsonl = os.path.join(path, \"dev_seen.jsonl\")\nval_unseen_jsonl = os.path.join(path, \"dev_unseen.jsonl\")\ntest_seen_jsonl = os.path.join(path, \"test_seen.jsonl\")\ntest_unseen_jsonl = os.path.join(path, \"test_unseen.jsonl\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.912405Z","iopub.execute_input":"2024-05-01T05:44:38.912679Z","iopub.status.idle":"2024-05-01T05:44:38.964818Z","shell.execute_reply.started":"2024-05-01T05:44:38.912649Z","shell.execute_reply":"2024-05-01T05:44:38.963877Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = HatefulMemesDataset(jsonl_file=train_jsonl, root_dir=path, transform=hm_transform)\nval_seen_dataset = HatefulMemesDataset(jsonl_file=val_seen_jsonl, root_dir=path, transform=hm_transform)\nval_unseen_dataset = HatefulMemesDataset(jsonl_file=val_unseen_jsonl, root_dir=path, transform=hm_transform)\ntest_seen_dataset = HatefulMemesDataset(jsonl_file=test_seen_jsonl, root_dir=path, transform=hm_transform)\ntest_unseen_dataset = HatefulMemesDataset(jsonl_file=test_unseen_jsonl, root_dir=path, transform=hm_transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:38.965763Z","iopub.execute_input":"2024-05-01T05:44:38.966043Z","iopub.status.idle":"2024-05-01T05:44:39.086188Z","shell.execute_reply.started":"2024-05-01T05:44:38.966020Z","shell.execute_reply":"2024-05-01T05:44:39.085407Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.087236Z","iopub.execute_input":"2024-05-01T05:44:39.087542Z","iopub.status.idle":"2024-05-01T05:44:39.141185Z","shell.execute_reply.started":"2024-05-01T05:44:39.087516Z","shell.execute_reply":"2024-05-01T05:44:39.140250Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.142453Z","iopub.execute_input":"2024-05-01T05:44:39.143240Z","iopub.status.idle":"2024-05-01T05:44:39.199857Z","shell.execute_reply.started":"2024-05-01T05:44:39.143208Z","shell.execute_reply":"2024-05-01T05:44:39.198871Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"val_dataset = ConcatDataset([val_seen_dataset, val_unseen_dataset])\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.201107Z","iopub.execute_input":"2024-05-01T05:44:39.201409Z","iopub.status.idle":"2024-05-01T05:44:39.255930Z","shell.execute_reply.started":"2024-05-01T05:44:39.201386Z","shell.execute_reply":"2024-05-01T05:44:39.254914Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_dataset = ConcatDataset([test_seen_dataset, test_unseen_dataset])\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.257086Z","iopub.execute_input":"2024-05-01T05:44:39.257683Z","iopub.status.idle":"2024-05-01T05:44:39.307952Z","shell.execute_reply.started":"2024-05-01T05:44:39.257656Z","shell.execute_reply":"2024-05-01T05:44:39.307107Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"def get_metrics_and_losses(losses, predictions, labels):\n  average_loss = losses.mean().item()\n  accuracy = (predictions == labels).sum().item() / labels.numel()\n  auroc = binary_auroc(predictions, labels)\n\n  return average_loss, accuracy, auroc","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.309032Z","iopub.execute_input":"2024-05-01T05:44:39.309310Z","iopub.status.idle":"2024-05-01T05:44:39.361632Z","shell.execute_reply.started":"2024-05-01T05:44:39.309280Z","shell.execute_reply":"2024-05-01T05:44:39.360861Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Resnet152","metadata":{}},{"cell_type":"code","source":"resnet152 = models.resnet152(pretrained=True)\nresnet152_fe = nn.Sequential(*list(resnet152.children())[:-1])\nfor p in resnet152_fe.parameters():\n    p.requires_grad = False\nresnet152_fe.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:39.362660Z","iopub.execute_input":"2024-05-01T05:44:39.363240Z","iopub.status.idle":"2024-05-01T05:44:42.546612Z","shell.execute_reply.started":"2024-05-01T05:44:39.363216Z","shell.execute_reply":"2024-05-01T05:44:42.545730Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n100%|██████████| 230M/230M [00:01<00:00, 166MB/s]  \n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (23): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (24): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (25): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (26): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (27): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (28): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (29): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (30): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (31): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (32): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (33): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (34): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (35): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\nbert_model = BertModel.from_pretrained(\"bert-base-uncased\")\nfor param in bert_model.parameters():\n    param.requires_grad = False\nbert_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:42.547808Z","iopub.execute_input":"2024-05-01T05:44:42.548089Z","iopub.status.idle":"2024-05-01T05:44:46.052060Z","shell.execute_reply.started":"2024-05-01T05:44:42.548064Z","shell.execute_reply":"2024-05-01T05:44:46.051090Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d27655ca0ab4fd29e10cbf3472b8f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556889764b53409c829fcaf082ac2770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"102e9798b3e841b78615ab551908d163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f01b7733740a412ba422bdfc108481dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23d593f98794c8bbfff6dbc380aaa0d"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Head","metadata":{}},{"cell_type":"code","source":"class SimpleHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.linear_stack = nn.Sequential(\n            nn.BatchNorm1d(2816),\n            nn.Linear(2816, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 2),\n        )\n    \n    def forward(self, x):\n        logits = self.linear_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:46.053558Z","iopub.execute_input":"2024-05-01T05:44:46.054028Z","iopub.status.idle":"2024-05-01T05:44:46.107685Z","shell.execute_reply.started":"2024-05-01T05:44:46.053992Z","shell.execute_reply":"2024-05-01T05:44:46.106797Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"head = SimpleHead()\nhead.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:46.109040Z","iopub.execute_input":"2024-05-01T05:44:46.109375Z","iopub.status.idle":"2024-05-01T05:44:46.188727Z","shell.execute_reply.started":"2024-05-01T05:44:46.109349Z","shell.execute_reply":"2024-05-01T05:44:46.187913Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"SimpleHead(\n  (linear_stack): Sequential(\n    (0): BatchNorm1d(2816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Linear(in_features=2816, out_features=1024, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=1024, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"lr = 1e-5\nepochs = 40\nweight_decay = 1e-3\naccumulate_steps = 4\n\n# Define criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Define optimizer\noptimizer = optim.Adam(head.parameters(), lr=lr, weight_decay=weight_decay)\n\n# Initialize learning rate scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n\n# Initialize early stopping parameters\nearly_stopping_counter = 0\nearly_stopping_patience = 5\nbest_validation_auroc = float('-inf')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:46.189991Z","iopub.execute_input":"2024-05-01T05:44:46.190325Z","iopub.status.idle":"2024-05-01T05:44:46.242726Z","shell.execute_reply.started":"2024-05-01T05:44:46.190293Z","shell.execute_reply":"2024-05-01T05:44:46.241879Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train model head\nfor e in range(epochs):\n    # Training\n    train_losses = torch.zeros(len(train_dataloader)).to(device)\n    train_predictions = torch.Tensor().to(device)\n    train_labels = torch.Tensor().to(device)\n\n    resnet152_fe.train()\n    bert_model.train()\n    head.train()\n\n    for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Epoch \" + str(e+1) + \" Training\"):\n        text = data['text']\n        image = data['image'].to(device).float()\n        labels = data['label'].to(device).to(torch.int64)\n\n        optimizer.zero_grad()\n\n        image_features = resnet152_fe(image).squeeze()\n\n        tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n        text_features = bert_model(**tokenized_input)\n\n        concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n        scores = torch.squeeze(head(concat_features))\n        predictions = scores.argmax(dim=-1)\n\n        loss = criterion(scores, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_losses[i] = loss\n        train_predictions = torch.cat((train_predictions, predictions))\n        train_labels = torch.cat((train_labels, labels))\n\n        train_average_loss, train_accuracy, train_auroc = get_metrics_and_losses(train_losses, train_predictions, train_labels)\n\n    # Validation\n    validate_losses = torch.zeros(len(val_dataloader)).to(device)\n    validate_predictions = torch.Tensor().to(device)\n    validate_labels = torch.Tensor().to(device)\n\n    resnet152_fe.eval()\n    bert_model.eval()\n    head.eval()\n\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=\"Epoch \" + str(e+1) + \" Validation\"):\n            text = data['text']\n            image = data['image'].to(device).float()\n            labels = data['label'].to(device).to(torch.int64)\n\n            image_features = resnet152_fe(image).squeeze()\n\n            tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n            text_features = bert_model(**tokenized_input)\n\n            concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n            scores = torch.squeeze(head(concat_features))\n            predictions = scores.argmax(dim=-1)\n\n            loss = criterion(scores, labels)\n\n            validate_losses[i] = loss\n            validate_predictions = torch.cat((validate_predictions, predictions), dim=0)\n            validate_labels = torch.cat((validate_labels, labels), dim=0)\n\n    validate_average_loss, validate_accuracy, validate_auroc = get_metrics_and_losses(validate_losses, validate_predictions, validate_labels)\n\n    # Update learning rate scheduler\n    scheduler.step(validate_auroc)\n\n    # Early stopping\n    if validate_auroc > best_validation_auroc:\n        best_validation_auroc = validate_auroc\n        early_stopping_counter = 0\n        # Save the best model\n        torch.save(head, model_path + \"/concat_bert_best.pt\")\n        print(\"New best model saved at epoch\", e+1)\n    else:\n        early_stopping_counter += 1\n        if early_stopping_counter >= early_stopping_patience:\n            print(\"Early stopping triggered at epoch\", e+1)\n            break\n\n    # Additional logging or tasks can be performed here\n    print(\"Epoch %d\" % (e+1))\n    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (train_average_loss, validate_average_loss))\n    print(\"Training Accuracy: %.4f. Validation Accuracy: %.4f. \" % (train_accuracy, validate_accuracy))\n    print(\"Training AUROC: %.4f. Validation AUROC: %.4f. \" % (train_auroc, validate_auroc))\n    print(\"-----------------------------------\")\n\nprint(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:44:46.243985Z","iopub.execute_input":"2024-05-01T05:44:46.244274Z","iopub.status.idle":"2024-05-01T06:10:28.368058Z","shell.execute_reply.started":"2024-05-01T05:44:46.244242Z","shell.execute_reply":"2024-05-01T06:10:28.367111Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Epoch 1 Training: 100%|██████████| 133/133 [03:50<00:00,  1.73s/it]\nEpoch 1 Validation: 100%|██████████| 17/17 [00:24<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 1\nEpoch 1\nTraining Loss: 0.6474. Validation Loss: 0.6957. \nTraining Accuracy: 0.6228. Validation Accuracy: 0.5740. \nTraining AUROC: 0.5683. Validation AUROC: 0.5210. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 Training: 100%|██████████| 133/133 [03:08<00:00,  1.42s/it]\nEpoch 2 Validation: 100%|██████████| 17/17 [00:22<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved at epoch 2\nEpoch 2\nTraining Loss: 0.6048. Validation Loss: 0.7022. \nTraining Accuracy: 0.6755. Validation Accuracy: 0.5904. \nTraining AUROC: 0.5847. Validation AUROC: 0.5348. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Training: 100%|██████████| 133/133 [03:11<00:00,  1.44s/it]\nEpoch 3 Validation: 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\nTraining Loss: 0.5899. Validation Loss: 0.7068. \nTraining Accuracy: 0.6878. Validation Accuracy: 0.5875. \nTraining AUROC: 0.5994. Validation AUROC: 0.5312. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Training: 100%|██████████| 133/133 [03:08<00:00,  1.42s/it]\nEpoch 4 Validation: 100%|██████████| 17/17 [00:22<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4\nTraining Loss: 0.5777. Validation Loss: 0.7067. \nTraining Accuracy: 0.6982. Validation Accuracy: 0.5817. \nTraining AUROC: 0.6137. Validation AUROC: 0.5275. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 Training: 100%|██████████| 133/133 [03:11<00:00,  1.44s/it]\nEpoch 5 Validation: 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5\nTraining Loss: 0.5669. Validation Loss: 0.7129. \nTraining Accuracy: 0.7104. Validation Accuracy: 0.5798. \nTraining AUROC: 0.6312. Validation AUROC: 0.5208. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 Training: 100%|██████████| 133/133 [03:16<00:00,  1.48s/it]\nEpoch 6 Validation: 100%|██████████| 17/17 [00:27<00:00,  1.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6\nTraining Loss: 0.5560. Validation Loss: 0.7105. \nTraining Accuracy: 0.7171. Validation Accuracy: 0.5846. \nTraining AUROC: 0.6373. Validation AUROC: 0.5281. \n-----------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 Training: 100%|██████████| 133/133 [03:12<00:00,  1.45s/it]\nEpoch 7 Validation: 100%|██████████| 17/17 [00:22<00:00,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping triggered at epoch 7\nTraining complete.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Rebuild the model architecture\nbest_head = torch.load(model_path + \"/concat_bert_best.pt\")\nbest_head.to(device)\n\n# Evaluate on test set\ntest_losses = torch.zeros(len(test_dataloader)).to(device)\ntest_predictions = torch.Tensor().to(device)\ntest_labels = torch.Tensor().to(device)\n\nbest_head.eval()\n\nwith torch.no_grad():\n    for i, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing\"):\n        text = data['text']\n        image = data['image'].to(device).float()\n        labels = data['label'].to(device).to(torch.int64)\n\n        image_features = resnet152_fe(image).squeeze()\n\n        tokenized_input = tokenizer(text, padding=True, return_tensors=\"pt\").to(device)\n        text_features = bert_model(**tokenized_input)\n\n        concat_features = torch.cat((image_features, text_features[\"pooler_output\"]), dim=1)\n\n        scores = torch.squeeze(best_head(concat_features))\n        predictions = scores.argmax(dim=-1)\n\n        loss = criterion(scores, labels)\n\n        test_losses[i] = loss\n        test_predictions = torch.cat((test_predictions, predictions), dim=0)\n        test_labels = torch.cat((test_labels, labels), dim=0)\n\ntest_average_loss, test_accuracy, test_auroc = get_metrics_and_losses(test_losses, test_predictions, test_labels)\n\nprint(\"Test Loss: %.4f\" % test_average_loss)\nprint(\"Test Accuracy: %.4f\" % test_accuracy)\nprint(\"Test AUROC: %.4f\" % test_auroc)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T06:10:28.369397Z","iopub.execute_input":"2024-05-01T06:10:28.369778Z","iopub.status.idle":"2024-05-01T06:11:45.732503Z","shell.execute_reply.started":"2024-05-01T06:10:28.369720Z","shell.execute_reply":"2024-05-01T06:11:45.731470Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 47/47 [01:17<00:00,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.6819\nTest Accuracy: 0.6080\nTest AUROC: 0.5406\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}